# NBA ReID æ¨ç†å·¥å…·

æ”¯æŒä¸‰ç§è§†é¢‘é‡è¯†åˆ«æ¨¡å‹çš„ç»Ÿä¸€æ¨ç†æ¥å£ï¼š**TimeSformer**ã€**MViT**ã€**UniFormerV2**

## ğŸ“ æ–‡ä»¶ç»“æ„

```
inference/
â”œâ”€â”€ README.md        # æœ¬æ–‡ä»¶ - ä½¿ç”¨è¯´æ˜
â”œâ”€â”€ __init__.py      # Python åŒ…åˆå§‹åŒ–
â””â”€â”€ inference.py     # æ ¸å¿ƒæ¨ç†æ¨¡å—
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### Python API ä½¿ç”¨

```python
from inference import ReIDInference
import torch

# åˆå§‹åŒ–æ¨ç†å™¨
inferencer = ReIDInference(
    model_name='timesformer',  # 'timesformer', 'mvit', 'uniformerv2'
    checkpoint_path='outputs/timesformer_app_ft/timesformer_app_model.pth',
    device='cuda:0'
)

# æå–ç‰¹å¾
video = torch.randn(1, 3, 32, 224, 224)  # [B, C, T, H, W]
features = inferencer.extract_features(video)
print(f"ç‰¹å¾å½¢çŠ¶: {features.shape}")
```

### å‘½ä»¤è¡Œä½¿ç”¨

```bash
python -m inference.inference \
    --model timesformer \
    --checkpoint outputs/timesformer_app_ft/timesformer_app_model.pth \
    --mode extract
```

## ğŸ¯ æ”¯æŒçš„æ¨¡å‹

| æ¨¡å‹ | ç‰¹ç‚¹ | æ¨èåœºæ™¯ |
|------|------|----------|
| **TimeSformer** | åˆ†å‰²æ—¶ç©ºæ³¨æ„åŠ›ï¼Œå¹³è¡¡æ€§èƒ½ | é€šç”¨åœºæ™¯ |
| **MViT** | å¤šå°ºåº¦ç‰¹å¾ï¼Œé€Ÿåº¦å¿« | å¿«é€Ÿæ¨ç† |
| **UniFormerV2** | å±€éƒ¨+å…¨å±€ï¼Œå‡†ç¡®ç‡é«˜ | æœ€ä½³æ€§èƒ½ |

## ï¿½ ä¸»è¦åŠŸèƒ½

### 1. ç‰¹å¾æå–
```python
features = inferencer.extract_features(video_tensor)
```

### 2. ç›¸ä¼¼åº¦è®¡ç®—
```python
similarity = inferencer.compute_similarity(
    query_feat, gallery_feat, metric='cosine'
)
```

### 3. Gallery æ’åº
```python
results = inferencer.rank_gallery(
    query_feat, gallery_feat, gallery_ids, top_k=10
)
```

### 4. ç‰¹å¾ä¿å­˜
```python
inferencer.save_features(features, 'output.npz')
```

## ğŸ“– å®Œæ•´ç¤ºä¾‹

```python
from inference import ReIDInference
import torch
import numpy as np

# åˆå§‹åŒ–
inferencer = ReIDInference(
    model_name='timesformer',
    checkpoint_path='outputs/timesformer_app_ft/timesformer_app_model.pth'
)

# å‡†å¤‡æ•°æ®
query_video = torch.randn(1, 3, 32, 224, 224)
gallery_videos = torch.randn(10, 3, 32, 224, 224)
gallery_ids = [f'person_{i}' for i in range(10)]

# æå–ç‰¹å¾
query_feat = inferencer.extract_features(query_video)
gallery_feat = inferencer.extract_features(gallery_videos)

# æ£€ç´¢æ’åº
results = inferencer.rank_gallery(
    query_feat, gallery_feat, gallery_ids, top_k=5
)

# æ˜¾ç¤ºç»“æœ
for r in results:
    print(f"Rank {r['rank']}: {r['id']} (ç›¸ä¼¼åº¦: {r['similarity']:.4f})")
```

## ï¿½ ä½¿ç”¨æŠ€å·§

### æ‰¹é‡å¤„ç†
```python
batch_size = 8
all_features = []
for i in range(0, num_videos, batch_size):
    batch = videos[i:i+batch_size]
    features = inferencer.extract_features(batch)
    all_features.append(features)
all_features = np.vstack(all_features)
```

### å¤šæ¨¡å‹é›†æˆ
```python
models = ['timesformer', 'mvit']
ensemble_feat = []
for model in models:
    inf = ReIDInference(model, checkpoints[model])
    feat = inf.extract_features(video)
    ensemble_feat.append(feat)
final_feat = np.mean(ensemble_feat, axis=0)
```

## âš™ï¸ ç¯å¢ƒè¦æ±‚

- Python >= 3.8
- PyTorch >= 1.10
- CUDA >= 11.0ï¼ˆGPUæ¨ç†ï¼‰
- å…¶ä»–ä¾èµ–è§é¡¹ç›®æ ¹ç›®å½•çš„ `environment.yml`

## ğŸ› å¸¸è§é—®é¢˜

**Q: æ˜¾å­˜ä¸è¶³ï¼Ÿ**  
A: å‡å° batch_size æˆ–ä½¿ç”¨ CPU
```python
inferencer = ReIDInference(..., device='cpu')
```

**Q: æ¨¡å‹åŠ è½½å¤±è´¥ï¼Ÿ**  
A: æ£€æŸ¥ checkpoint è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰

## ğŸ“ API å‚è€ƒ

### ReIDInference ç±»

**åˆå§‹åŒ–å‚æ•°ï¼š**
- `model_name`: æ¨¡å‹åç§° ('timesformer', 'mvit', 'uniformerv2')
- `checkpoint_path`: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
- `config_path`: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
- `device`: è®¡ç®—è®¾å¤‡ï¼ˆé»˜è®¤: 'cuda:0'ï¼‰

**ä¸»è¦æ–¹æ³•ï¼š**
- `extract_features(video_tensor)`: æå–ç‰¹å¾
- `compute_similarity(query_feat, gallery_feat, metric)`: è®¡ç®—ç›¸ä¼¼åº¦
- `rank_gallery(query_feat, gallery_feat, ids, top_k)`: æ’åºæ£€ç´¢
- `save_features(features, path, metadata)`: ä¿å­˜ç‰¹å¾

**è¾“å…¥æ ¼å¼ï¼š**
- è§†é¢‘å¼ é‡ï¼š`[B, C, T, H, W]` = `[batch_size, 3, 32, 224, 224]`

---

æ›´å¤šä¿¡æ¯è¯·å‚è€ƒé¡¹ç›®æ–‡æ¡£æˆ–æºä»£ç æ³¨é‡Šã€‚
